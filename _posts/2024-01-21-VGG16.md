---
layout: post
title:  "Implementing VGG16"
date:   2024-01-21 12:49:07 -0500
---

### Motivation
During my deep learning class of 2023, we were asked to build a slightly
different version of the VGG16 with pytorch. The program was originaly coded in
a jupyter notebook.

### What is the VGG16 architecture
VGG stands for Visual Geometry Group, a research group at the University of
Oxford. It is a well known convolutional neural network used in image
classification. Published in a 2014 paper, it gained recognition for its deep
stacking of convolution layers, utilization of small filter sizes, and adherence
to a uniform architecture.

## Implementing the VGG16



```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
device = "cuda" if torch.cuda.is_available() else "cpu"

# fix random state
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
torch.cuda.manual_seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```


```python
class VGG16(nn.Module):
  """This class implements the VGG-16 architecture in PyTorch"""

  def __init__(self, activation_str="relu"):
    """
      Constructor for the VGG16 class.

      activation_str: string, default "relu"
        Activation function to use.
    """
    super(VGG16, self).__init__()

    self.n_classes = 10
    self.activation_str = activation_str

    self.conv_layer_1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = "same")
    self.conv_layer_2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = "same")

    self.conv_layer_3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = "same")
    self.conv_layer_4 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = "same")

    self.conv_layer_5 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = "same")
    self.conv_layer_6 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = "same")
    self.conv_layer_7 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = "same")

    self.conv_layer_8 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_9 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_10 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")

    self.conv_layer_11 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_12 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_13 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")

    # Add 2D batch normalization after every convolutional layer
    self.conv_layer_1_bn  = nn.BatchNorm2d(num_features = 64)
    self.conv_layer_2_bn  = nn.BatchNorm2d(num_features = 64)
    self.conv_layer_3_bn  = nn.BatchNorm2d(num_features = 128)
    self.conv_layer_4_bn  = nn.BatchNorm2d(num_features = 128)
    self.conv_layer_5_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_6_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_7_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_8_bn  = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_9_bn  = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_10_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_11_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_12_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_13_bn = nn.BatchNorm2d(num_features = 512)

    self.max_pool_layer_1 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_2 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_3 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_4 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_5 = nn.MaxPool2d(kernel_size=2, stride = 2)

    self.fc_1 = nn.Linear(in_features = 25088, out_features = 4096)
    self.fc_2 = nn.Linear(in_features = 4096, out_features = 4096)
    self.fc_3 = nn.Linear(in_features = 4096, out_features = self.n_classes)

    # Initialize the weights of each trainable layer of the network using xavier_uniform initialization
    def xavier_init(layer):
      for k,v in layer.named_parameters():
        if k == 'weight':
          init.xavier_uniform_(v)

    xavier_init(self.conv_layer_1)
    xavier_init(self.conv_layer_2)
    xavier_init(self.conv_layer_3)
    xavier_init(self.conv_layer_4)
    xavier_init(self.conv_layer_5)
    xavier_init(self.conv_layer_6)
    xavier_init(self.conv_layer_7)
    xavier_init(self.conv_layer_8)
    xavier_init(self.conv_layer_9)
    xavier_init(self.conv_layer_10)
    xavier_init(self.conv_layer_11)
    xavier_init(self.conv_layer_12)
    xavier_init(self.conv_layer_13)

    xavier_init(self.fc_1)
    xavier_init(self.fc_2)
    xavier_init(self.fc_3)

  def activation(self, input):
    """
      input: Tensor
        Input on which the activation is applied.

      Output: Result of activation function applied on input.
        E.g. if self.activation_str is "relu", return relu(input).
    """
    if self.activation_str == "relu":
      a = nn.ReLU()
      return a(input)
    elif self.activation_str == "tanh":
      a = nn.Tanh()
      return a(input)
    else:
      raise Exception("Invalid activation")
    return 0


  def get_first_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the first convolution layer.
    """
    return self.conv_layer_1.weight.clone().cpu().detach().numpy()

  def get_last_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the last convolution layer.
    """
    return self.conv_layer_13.weight.clone().cpu().detach().numpy()

  def forward(self, x):
    """
      x: Tensor
        Input to the network.

      Outputs: Returns the output of the forward pass of the network.
    """
    x = self.conv_layer_1(x)
    x = self.conv_layer_1_bn(x)
    x = self.activation(x)


    x = self.conv_layer_2(x)
    x = self.conv_layer_2_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_1(x)

    x = self.conv_layer_3(x)
    x = self.conv_layer_3_bn(x)
    x = self.activation(x)

    x = self.conv_layer_4(x)
    x = self.conv_layer_4_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_2(x)

    x = self.conv_layer_5(x)
    x = self.conv_layer_5_bn(x)
    x = self.activation(x)

    x = self.conv_layer_6(x)
    x = self.conv_layer_6_bn(x)
    x = self.activation(x)

    x = self.conv_layer_7(x)
    x = self.conv_layer_7_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_3(x)

    x = self.conv_layer_8(x)
    x = self.conv_layer_8_bn(x)
    x = self.activation(x)

    x = self.conv_layer_9(x)
    x = self.conv_layer_9_bn(x)
    x = self.activation(x)

    x = self.conv_layer_10(x)
    x = self.conv_layer_10_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_4(x)

    x = self.conv_layer_11(x)
    x = self.conv_layer_11_bn(x)
    x = self.activation(x)

    x = self.conv_layer_12(x)
    x = self.conv_layer_12_bn(x)
    x = self.activation(x)

    x = self.conv_layer_13(x)
    x = self.conv_layer_13_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_5(x)

    x = torch.flatten(x, start_dim = 1)
    x = self.fc_1(x)
    x = self.activation(x)
    x = self.fc_2(x)
    x = self.activation(x)
    x = self.fc_3(x)
    #x = self.activation(x)
    softmax = nn.Softmax(dim = 1)
    o = softmax(x)

    return o
  def last_conv(self, x):
    x = self.conv_layer_1(x)
    x = self.conv_layer_1_bn(x)
    x = self.activation(x)


    x = self.conv_layer_2(x)
    x = self.conv_layer_2_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_1(x)

    x = self.conv_layer_3(x)
    x = self.conv_layer_3_bn(x)
    x = self.activation(x)

    x = self.conv_layer_4(x)
    x = self.conv_layer_4_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_2(x)

    x = self.conv_layer_5(x)
    x = self.conv_layer_5_bn(x)
    x = self.activation(x)

    x = self.conv_layer_6(x)
    x = self.conv_layer_6_bn(x)
    x = self.activation(x)

    x = self.conv_layer_7(x)
    x = self.conv_layer_7_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_3(x)

    x = self.conv_layer_8(x)
    x = self.conv_layer_8_bn(x)
    x = self.activation(x)

    x = self.conv_layer_9(x)
    x = self.conv_layer_9_bn(x)
    x = self.activation(x)

    x = self.conv_layer_10(x)
    x = self.conv_layer_10_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_4(x)

    x = self.conv_layer_11(x)
    x = self.conv_layer_11_bn(x)
    x = self.activation(x)

    x = self.conv_layer_12(x)
    x = self.conv_layer_12_bn(x)
    x = self.activation(x)

    x = self.conv_layer_13(x)
    x = self.conv_layer_13_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_5(x)
    return x
```

<!-- ### Question 3.3 -->
<!---->
<!---->
<!-- ```python -->
<!-- def get_cifar10(): -->
<!--   normalize = transforms.Normalize( -->
<!--       mean=[0.4914, 0.4822, 0.4465], -->
<!--       std=[0.2023, 0.1994, 0.2010], -->
<!--   ) -->
<!---->
<!--   # define transforms -->
<!--   transform = transforms.Compose([ -->
<!--           transforms.Resize((227,227)), -->
<!--           transforms.ToTensor(), -->
<!--           normalize, -->
<!--   ]) -->
<!---->
<!--   train_dataset = torchvision.datasets.CIFAR10( -->
<!--       root='./data', train=True, download=True, transform=transform) -->
<!--   train_loader = torch.utils.data.DataLoader( -->
<!--       train_dataset, batch_size=64, shuffle=True, num_workers=2) -->
<!---->
<!--   val_dataset = torchvision.datasets.CIFAR10( -->
<!--       root='./data', train=False, download=True, transform=transform) -->
<!--   val_loader = torch.utils.data.DataLoader( -->
<!--       val_dataset, batch_size=64, shuffle=False, num_workers=2) -->
<!---->
<!--   return train_loader, val_loader -->
<!---->
<!-- def train_loop(epoch, model, train_loader, criterion, optimizer): -->
<!--   """ -->
<!--     epoch: int -->
<!--       Number of the current training epoch (starting from 0). -->
<!--     model: VGG16 -->
<!--       The model to train, which is an instance of the VGG16 class. -->
<!--     train_loader: DataLoader -->
<!--       The training dataloader. -->
<!--     criterion: Module -->
<!--       A Module object that evaluates the crossentropy loss. -->
<!--     optimizer: Optimizer -->
<!--       An Optimizer object for the Adam optimizer. -->
<!---->
<!--     Outputs: Returns average train_acc and train_loss for the current epoch. -->
<!--   """ -->
<!--   train_acc = 0. -->
<!--   train_loss = 0. -->
<!--   counter = 0 -->
<!--   for batch in train_loader: -->
<!--     for param in model.parameters(): # Recommended to save RAM -->
<!--       param.grad = None -->
<!--     x,y = batch -->
<!--     if device == 'cuda': -->
<!--       x = x.cuda() -->
<!--       y = y.cuda() -->
<!--     ans = model(x) -->
<!--     loss = criterion(ans, y) -->
<!--     loss.backward() -->
<!--     optimizer.step() -->
<!--     n = y.size(0) -->
<!--     train_loss += loss.sum().data.cpu().numpy() * n -->
<!--     counter += n -->
<!--     if counter % 9984 == 0: -->
<!--       print(f"iteration: {counter}") -->
<!--     correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor) -->
<!--     train_acc += correct -->
<!--   train_acc /= counter -->
<!--   train_loss /= counter -->
<!--   print(f"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}") -->
<!--   return train_acc, train_loss -->
<!---->
<!-- def valid_loop(epoch, model, val_loader, criterion): -->
<!--   """ -->
<!--     epoch: int -->
<!--       Number of the current epoch (starting from 0). -->
<!--     model: VGG16 -->
<!--       The model to train, which is an instance of the VGG16 class. -->
<!--     val_loader: DataLoader -->
<!--       The validation dataloader. -->
<!--     criterion: Module -->
<!--       A Module object that evaluates the crossentropy loss. -->
<!---->
<!--     Outputs: Returns average val_acc and val_loss for the current epoch. -->
<!--   """ -->
<!--   val_acc = 0. -->
<!--   val_loss = 0. -->
<!--   counter = 0 -->
<!---->
<!--   with torch.no_grad(): -->
<!--     for batch in val_loader: -->
<!--       for param in model.parameters(): -->
<!--         param.grad = None -->
<!--       x,y = batch -->
<!--       if device == 'cuda': -->
<!--         x = x.cuda() -->
<!--         y = y.cuda() -->
<!--       ans = model(x) -->
<!--       loss = criterion(ans, y) -->
<!--       n = y.size(0) -->
<!--       val_loss += loss.sum().data.cpu().numpy() * n -->
<!--       counter += n -->
<!--       correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor) -->
<!--       val_acc += correct -->
<!--     val_acc /= counter -->
<!--     val_loss /= counter -->
<!---->
<!--   print(f"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}") -->
<!--   return val_acc, val_loss -->
<!-- ``` -->
<!---->
<!---->
<!-- ```python -->
<!-- if __name__ == "__main__": -->
<!--   activation_str = "relu" -->
<!--   train_accs, train_losses, val_accs, val_losses = [], [], [], [] -->
<!--   n_epochs = 15 -->
<!---->
<!--   model = VGG16( -->
<!--     activation_str=activation_str, -->
<!--   ).to(device) -->
<!--   criterion = nn.CrossEntropyLoss() -->
<!--   optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) -->
<!---->
<!--   train_loader, val_loader = get_cifar10() -->
<!--   training_vgg16 = False -->
<!--   model_save_name = 'vgg16.pt' -->
<!--   path = F"/content/gdrive/My Drive/{model_save_name}" -->
<!--   if training_vgg16: -->
<!--     for epoch in range(n_epochs): -->
<!--       # Training -->
<!--       train_acc, train_loss = train_loop(epoch, model, train_loader, criterion, optimizer) -->
<!--       train_accs.append(train_acc) -->
<!--       train_losses.append(train_loss) -->
<!---->
<!--       # Validation -->
<!--       val_acc, val_loss = valid_loop(epoch, model, val_loader, criterion) -->
<!--       val_accs.append(val_acc) -->
<!--       val_losses.append(val_loss) -->
<!---->
<!--     torch.save(model.state_dict(), path) -->
<!--   else: -->
<!--     model.load_state_dict(torch.load(path)) -->
<!--   model.eval() -->
<!-- ``` -->
<!--     Final epoch accuracy -->
<!--     Epoch: 14 | Train Acc: 0.919460 | Train Loss: 1.546990 -->
<!--     Epoch: 14 | Val Acc: 0.778600   | Val Loss: 1.684834 -->
<!---->
<!---->
<!---->
<!-- ```python -->
<!-- if __name__ == "__main__": -->
<!--   vis_image = None -->
<!--   for data, labels in val_loader: -->
<!--     vis_image = data[12].unsqueeze(0) -->
<!---->
<!--   print(vis_image.shape) -->
<!-- ``` -->
<!---->
<!--     torch.Size([1, 3, 227, 227]) -->
<!---->
<!---->
<!-- ```python -->
<!-- def get_cifar10(): -->
<!--   normalize = transforms.Normalize( -->
<!--       mean=[0.4914, 0.4822, 0.4465], -->
<!--       std=[0.2023, 0.1994, 0.2010], -->
<!--   ) -->
<!---->
<!--   # define transforms -->
<!--   transform = transforms.Compose([ -->
<!--           transforms.Resize((227,227)), -->
<!--           transforms.ToTensor(), -->
<!--           normalize, -->
<!--   ]) -->
<!---->
<!--   train_dataset = torchvision.datasets.CIFAR10( -->
<!--       root='./data', train=True, download=True, transform=transform) -->
<!--   train_loader = torch.utils.data.DataLoader( -->
<!--       train_dataset, batch_size=64, shuffle=True, num_workers=2) -->
<!---->
<!--   val_dataset = torchvision.datasets.CIFAR10( -->
<!--       root='./data', train=False, download=True, transform=transform) -->
<!--   val_loader = torch.utils.data.DataLoader( -->
<!--       val_dataset, batch_size=64, shuffle=False, num_workers=2) -->
<!---->
<!--   return train_loader, val_loader -->
<!---->
<!-- def train_loop(epoch, model, train_loader, criterion, optimizer): -->
<!--   """ -->
<!--     epoch: int -->
<!--       Number of the current training epoch (starting from 0). -->
<!--     model: VGG16 -->
<!--       The model to train, which is an instance of the VGG16 class. -->
<!--     train_loader: DataLoader -->
<!--       The training dataloader. -->
<!--     criterion: Module -->
<!--       A Module object that evaluates the crossentropy loss. -->
<!--     optimizer: Optimizer -->
<!--       An Optimizer object for the Adam optimizer. -->
<!---->
<!--     Outputs: Returns average train_acc and train_loss for the current epoch. -->
<!--   """ -->
<!--   train_acc = 0. -->
<!--   train_loss = 0. -->
<!--   counter = 0 -->
<!--   for batch in train_loader: -->
<!--     for param in model.parameters(): # Recommended to save RAM -->
<!--       param.grad = None -->
<!--     x,y = batch -->
<!--     if device == 'cuda': -->
<!--       x = x.cuda() -->
<!--       y = y.cuda() -->
<!--     ans = model(x) -->
<!--     loss = criterion(ans, y) -->
<!--     loss.backward() -->
<!--     optimizer.step() -->
<!--     n = y.size(0) -->
<!--     train_loss += loss.sum().data.cpu().numpy() * n -->
<!--     counter += n -->
<!--     if counter % 9984 == 0: -->
<!--       print(f"iteration: {counter}") -->
<!--     correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor) -->
<!--     train_acc += correct -->
<!--   train_acc /= counter -->
<!--   train_loss /= counter -->
<!--   print(f"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}") -->
<!--   return train_acc, train_loss -->
<!---->
<!-- def valid_loop(epoch, model, val_loader, criterion): -->
<!--   """ -->
<!--     epoch: int -->
<!--       Number of the current epoch (starting from 0). -->
<!--     model: VGG16 -->
<!--       The model to train, which is an instance of the VGG16 class. -->
<!--     val_loader: DataLoader -->
<!--       The validation dataloader. -->
<!--     criterion: Module -->
<!--       A Module object that evaluates the crossentropy loss. -->
<!---->
<!--     Outputs: Returns average val_acc and val_loss for the current epoch. -->
<!--   """ -->
<!--   val_acc = 0. -->
<!--   val_loss = 0. -->
<!--   counter = 0 -->
<!---->
<!--   with torch.no_grad(): -->
<!--     for batch in val_loader: -->
<!--       for param in model.parameters(): -->
<!--         param.grad = None -->
<!--       x,y = batch -->
<!--       if device == 'cuda': -->
<!--         x = x.cuda() -->
<!--         y = y.cuda() -->
<!--       ans = model(x) -->
<!--       loss = criterion(ans, y) -->
<!--       n = y.size(0) -->
<!--       val_loss += loss.sum().data.cpu().numpy() * n -->
<!--       counter += n -->
<!--       correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor) -->
<!--       val_acc += correct -->
<!--     val_acc /= counter -->
<!--     val_loss /= counter -->
<!---->
<!--   print(f"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}") -->
<!--   return val_acc, val_loss -->
<!-- ``` -->
<!---->
<!---->
