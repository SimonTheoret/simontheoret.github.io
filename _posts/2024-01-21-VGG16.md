---
layout: post
title:  "Implementing the VGG16"
date:   2024-01-21 12:49:07 -0500
---

### Motivation
During my deep learning class of 2023, we were asked to build a slightly
different version of the VGG16 with pytorch. The program was originaly coded in
a jupyter notebook.

### What is the VGG16 architecture
VGG stands for Visual Geometry Group, a research group at the University of
Oxford. It is a well known convolutional neural network used in image
classification. Published in a 2014 paper, it gained recognition for its deep
stacking of convolution layers, utilization of small filter sizes, and adherence
to a uniform architecture.

## Implementing the VGG16



```python
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.nn.init as init
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
device = "cuda" if torch.cuda.is_available() else "cpu"

# fix random state
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
torch.cuda.manual_seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```


```python
class VGG16(nn.Module):
  """This class implements the VGG-16 architecture in PyTorch"""

  def __init__(self, activation_str="relu"):
    """
      Constructor for the VGG16 class.

      activation_str: string, default "relu"
        Activation function to use.
    """
    super(VGG16, self).__init__()

    self.n_classes = 10
    self.activation_str = activation_str

    self.conv_layer_1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = "same")
    self.conv_layer_2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = "same")

    self.conv_layer_3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = "same")
    self.conv_layer_4 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = "same")

    self.conv_layer_5 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = "same")
    self.conv_layer_6 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = "same")
    self.conv_layer_7 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = "same")

    self.conv_layer_8 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_9 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_10 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")

    self.conv_layer_11 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_12 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")
    self.conv_layer_13 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same")

    # Add 2D batch normalization after every convolutional layer
    self.conv_layer_1_bn  = nn.BatchNorm2d(num_features = 64)
    self.conv_layer_2_bn  = nn.BatchNorm2d(num_features = 64)
    self.conv_layer_3_bn  = nn.BatchNorm2d(num_features = 128)
    self.conv_layer_4_bn  = nn.BatchNorm2d(num_features = 128)
    self.conv_layer_5_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_6_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_7_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_8_bn  = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_9_bn  = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_10_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_11_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_12_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_13_bn = nn.BatchNorm2d(num_features = 512)

    self.max_pool_layer_1 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_2 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_3 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_4 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_5 = nn.MaxPool2d(kernel_size=2, stride = 2)

    self.fc_1 = nn.Linear(in_features = 25088, out_features = 4096)
    self.fc_2 = nn.Linear(in_features = 4096, out_features = 4096)
    self.fc_3 = nn.Linear(in_features = 4096, out_features = self.n_classes)

    # Initialize the weights of each trainable layer of the network using xavier_uniform initialization
    def xavier_init(layer):
      for k,v in layer.named_parameters():
        if k == 'weight':
          init.xavier_uniform_(v)

    xavier_init(self.conv_layer_1)
    xavier_init(self.conv_layer_2)
    xavier_init(self.conv_layer_3)
    xavier_init(self.conv_layer_4)
    xavier_init(self.conv_layer_5)
    xavier_init(self.conv_layer_6)
    xavier_init(self.conv_layer_7)
    xavier_init(self.conv_layer_8)
    xavier_init(self.conv_layer_9)
    xavier_init(self.conv_layer_10)
    xavier_init(self.conv_layer_11)
    xavier_init(self.conv_layer_12)
    xavier_init(self.conv_layer_13)

    xavier_init(self.fc_1)
    xavier_init(self.fc_2)
    xavier_init(self.fc_3)

  def activation(self, input):
    """
      input: Tensor
        Input on which the activation is applied.

      Output: Result of activation function applied on input.
        E.g. if self.activation_str is "relu", return relu(input).
    """
    if self.activation_str == "relu":
      a = nn.ReLU()
      return a(input)
    elif self.activation_str == "tanh":
      a = nn.Tanh()
      return a(input)
    else:
      raise Exception("Invalid activation")
    return 0


  def get_first_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the first convolution layer.
    """
    return self.conv_layer_1.weight.clone().cpu().detach().numpy()

  def get_last_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the last convolution layer.
    """
    return self.conv_layer_13.weight.clone().cpu().detach().numpy()

  def forward(self, x):
    """
      x: Tensor
        Input to the network.

      Outputs: Returns the output of the forward pass of the network.
    """
    x = self.conv_layer_1(x)
    x = self.conv_layer_1_bn(x)
    x = self.activation(x)


    x = self.conv_layer_2(x)
    x = self.conv_layer_2_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_1(x)

    x = self.conv_layer_3(x)
    x = self.conv_layer_3_bn(x)
    x = self.activation(x)

    x = self.conv_layer_4(x)
    x = self.conv_layer_4_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_2(x)

    x = self.conv_layer_5(x)
    x = self.conv_layer_5_bn(x)
    x = self.activation(x)

    x = self.conv_layer_6(x)
    x = self.conv_layer_6_bn(x)
    x = self.activation(x)

    x = self.conv_layer_7(x)
    x = self.conv_layer_7_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_3(x)

    x = self.conv_layer_8(x)
    x = self.conv_layer_8_bn(x)
    x = self.activation(x)

    x = self.conv_layer_9(x)
    x = self.conv_layer_9_bn(x)
    x = self.activation(x)

    x = self.conv_layer_10(x)
    x = self.conv_layer_10_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_4(x)

    x = self.conv_layer_11(x)
    x = self.conv_layer_11_bn(x)
    x = self.activation(x)

    x = self.conv_layer_12(x)
    x = self.conv_layer_12_bn(x)
    x = self.activation(x)

    x = self.conv_layer_13(x)
    x = self.conv_layer_13_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_5(x)

    x = torch.flatten(x, start_dim = 1)
    x = self.fc_1(x)
    x = self.activation(x)
    x = self.fc_2(x)
    x = self.activation(x)
    x = self.fc_3(x)
    #x = self.activation(x)
    softmax = nn.Softmax(dim = 1)
    o = softmax(x)

    return o
  def last_conv(self, x):
    x = self.conv_layer_1(x)
    x = self.conv_layer_1_bn(x)
    x = self.activation(x)


    x = self.conv_layer_2(x)
    x = self.conv_layer_2_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_1(x)

    x = self.conv_layer_3(x)
    x = self.conv_layer_3_bn(x)
    x = self.activation(x)

    x = self.conv_layer_4(x)
    x = self.conv_layer_4_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_2(x)

    x = self.conv_layer_5(x)
    x = self.conv_layer_5_bn(x)
    x = self.activation(x)

    x = self.conv_layer_6(x)
    x = self.conv_layer_6_bn(x)
    x = self.activation(x)

    x = self.conv_layer_7(x)
    x = self.conv_layer_7_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_3(x)

    x = self.conv_layer_8(x)
    x = self.conv_layer_8_bn(x)
    x = self.activation(x)

    x = self.conv_layer_9(x)
    x = self.conv_layer_9_bn(x)
    x = self.activation(x)

    x = self.conv_layer_10(x)
    x = self.conv_layer_10_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_4(x)

    x = self.conv_layer_11(x)
    x = self.conv_layer_11_bn(x)
    x = self.activation(x)

    x = self.conv_layer_12(x)
    x = self.conv_layer_12_bn(x)
    x = self.activation(x)

    x = self.conv_layer_13(x)
    x = self.conv_layer_13_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_5(x)
    return x
```

### Question 3.3


```python
def get_cifar10():
  normalize = transforms.Normalize(
      mean=[0.4914, 0.4822, 0.4465],
      std=[0.2023, 0.1994, 0.2010],
  )

  # define transforms
  transform = transforms.Compose([
          transforms.Resize((227,227)),
          transforms.ToTensor(),
          normalize,
  ])

  train_dataset = torchvision.datasets.CIFAR10(
      root='./data', train=True, download=True, transform=transform)
  train_loader = torch.utils.data.DataLoader(
      train_dataset, batch_size=64, shuffle=True, num_workers=2)

  val_dataset = torchvision.datasets.CIFAR10(
      root='./data', train=False, download=True, transform=transform)
  val_loader = torch.utils.data.DataLoader(
      val_dataset, batch_size=64, shuffle=False, num_workers=2)

  return train_loader, val_loader

def train_loop(epoch, model, train_loader, criterion, optimizer):
  """
    epoch: int
      Number of the current training epoch (starting from 0).
    model: VGG16
      The model to train, which is an instance of the VGG16 class.
    train_loader: DataLoader
      The training dataloader.
    criterion: Module
      A Module object that evaluates the crossentropy loss.
    optimizer: Optimizer
      An Optimizer object for the Adam optimizer.

    Outputs: Returns average train_acc and train_loss for the current epoch.
  """
  train_acc = 0.
  train_loss = 0.
  counter = 0
  for batch in train_loader:
    for param in model.parameters(): # Recommended to save RAM
      param.grad = None
    x,y = batch
    if device == 'cuda':
      x = x.cuda()
      y = y.cuda()
    ans = model(x)
    loss = criterion(ans, y)
    loss.backward()
    optimizer.step()
    n = y.size(0)
    train_loss += loss.sum().data.cpu().numpy() * n
    counter += n
    if counter % 9984 == 0:
      print(f"iteration: {counter}")
    correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor)
    train_acc += correct
  train_acc /= counter
  train_loss /= counter
  print(f"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}")
  return train_acc, train_loss

def valid_loop(epoch, model, val_loader, criterion):
  """
    epoch: int
      Number of the current epoch (starting from 0).
    model: VGG16
      The model to train, which is an instance of the VGG16 class.
    val_loader: DataLoader
      The validation dataloader.
    criterion: Module
      A Module object that evaluates the crossentropy loss.

    Outputs: Returns average val_acc and val_loss for the current epoch.
  """
  val_acc = 0.
  val_loss = 0.
  counter = 0

  with torch.no_grad():
    for batch in val_loader:
      for param in model.parameters():
        param.grad = None
      x,y = batch
      if device == 'cuda':
        x = x.cuda()
        y = y.cuda()
      ans = model(x)
      loss = criterion(ans, y)
      n = y.size(0)
      val_loss += loss.sum().data.cpu().numpy() * n
      counter += n
      correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor)
      val_acc += correct
    val_acc /= counter
    val_loss /= counter

  print(f"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}")
  return val_acc, val_loss
```


```python
if __name__ == "__main__":
  activation_str = "relu"
  train_accs, train_losses, val_accs, val_losses = [], [], [], []
  n_epochs = 15

  model = VGG16(
    activation_str=activation_str,
  ).to(device)
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

  train_loader, val_loader = get_cifar10()
  training_vgg16 = False
  model_save_name = 'vgg16.pt'
  path = F"/content/gdrive/My Drive/{model_save_name}"
  if training_vgg16:
    for epoch in range(n_epochs):
      # Training
      train_acc, train_loss = train_loop(epoch, model, train_loader, criterion, optimizer)
      train_accs.append(train_acc)
      train_losses.append(train_loss)

      # Validation
      val_acc, val_loss = valid_loop(epoch, model, val_loader, criterion)
      val_accs.append(val_acc)
      val_losses.append(val_loss)

    torch.save(model.state_dict(), path)
  else:
    model.load_state_dict(torch.load(path))
  model.eval()
```

    Files already downloaded and verified
    Files already downloaded and verified
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 0 | Train Acc: 0.386000 | Train Loss: 2.075628
    Epoch: 0 | Val Acc: 0.465500   | Val Loss: 1.997571
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 1 | Train Acc: 0.506640 | Train Loss: 1.955509
    Epoch: 1 | Val Acc: 0.540100   | Val Loss: 1.920677
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 2 | Train Acc: 0.571980 | Train Loss: 1.891163
    Epoch: 2 | Val Acc: 0.571000   | Val Loss: 1.889987
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 3 | Train Acc: 0.618920 | Train Loss: 1.844378
    Epoch: 3 | Val Acc: 0.595300   | Val Loss: 1.866361
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 4 | Train Acc: 0.692820 | Train Loss: 1.772913
    Epoch: 4 | Val Acc: 0.674900   | Val Loss: 1.787175
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 5 | Train Acc: 0.736960 | Train Loss: 1.729299
    Epoch: 5 | Val Acc: 0.704800   | Val Loss: 1.757735
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 6 | Train Acc: 0.770800 | Train Loss: 1.696808
    Epoch: 6 | Val Acc: 0.729700   | Val Loss: 1.735513
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 7 | Train Acc: 0.799800 | Train Loss: 1.668198
    Epoch: 7 | Val Acc: 0.740100   | Val Loss: 1.724284
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 8 | Train Acc: 0.825480 | Train Loss: 1.642230
    Epoch: 8 | Val Acc: 0.752000   | Val Loss: 1.711529
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 9 | Train Acc: 0.844780 | Train Loss: 1.623155
    Epoch: 9 | Val Acc: 0.754600   | Val Loss: 1.709282
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 10 | Train Acc: 0.865360 | Train Loss: 1.602967
    Epoch: 10 | Val Acc: 0.767200   | Val Loss: 1.696773
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 11 | Train Acc: 0.882660 | Train Loss: 1.585695
    Epoch: 11 | Val Acc: 0.768400   | Val Loss: 1.696470
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 12 | Train Acc: 0.896140 | Train Loss: 1.571818
    Epoch: 12 | Val Acc: 0.778700   | Val Loss: 1.684127
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 13 | Train Acc: 0.910900 | Train Loss: 1.557102
    Epoch: 13 | Val Acc: 0.780000   | Val Loss: 1.682529
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 14 | Train Acc: 0.919460 | Train Loss: 1.546990
    Epoch: 14 | Val Acc: 0.778600   | Val Loss: 1.684834


### Questions 3.4 to 3.10



```python
if __name__ == "__main__":
  vis_image = None
  for data, labels in val_loader:
    vis_image = data[12].unsqueeze(0)

  print(vis_image.shape)
```

    torch.Size([1, 3, 227, 227])


# Question 3.4: Implementing a different architecture


```python
# Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchsummary import summary
import torch.nn.init as init
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms
device = "cuda" if torch.cuda.is_available() else "cpu"

# Fix random seed, DO NOT CHANGE
torch.manual_seed(0)
torch.cuda.manual_seed_all(0)
torch.cuda.manual_seed(0)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
```


```python
class NewModel(nn.Module):
  """This class implements the NewModel architecture in PyTorch"""

  def __init__(self, activation_str="relu"):
    """
      Constructor for the NewModel class.

      activation_str: string, default "relu"
        Activation function to use.
    """
    super(NewModel, self).__init__()

    self.n_classes = 10
    self.activation_str = activation_str

    self.conv_layer_1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding = "same", bias=False)
    self.conv_layer_2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding = "same", bias = False)

    self.conv_layer_3 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_4 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, padding = "same", bias = False)

    self.conv_layer_5 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_6 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_7 = nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, padding = "same", bias = False)

    self.conv_layer_8 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_9 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_10 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same", bias = False)

    self.conv_layer_11 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_12 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_13 = nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, padding = "same", bias = False)

    self.conv_layer_14 = nn.Conv2d(in_channels = 512, out_channels = 1024, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_15 = nn.Conv2d(in_channels = 1024, out_channels = 1024, kernel_size = 3, padding = "same", bias = False)
    self.conv_layer_16 = nn.Conv2d(in_channels = 1024, out_channels = 256, kernel_size = 1, padding = "valid", bias = False)

    # Add 2D batch normalization after every convolutional layer
    self.conv_layer_1_bn  = nn.BatchNorm2d(num_features = 64)
    self.conv_layer_2_bn  = nn.BatchNorm2d(num_features = 64)
    self.conv_layer_3_bn  = nn.BatchNorm2d(num_features = 128)
    self.conv_layer_4_bn  = nn.BatchNorm2d(num_features = 128)
    self.conv_layer_5_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_6_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_7_bn  = nn.BatchNorm2d(num_features = 256)
    self.conv_layer_8_bn  = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_9_bn  = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_10_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_11_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_12_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_13_bn = nn.BatchNorm2d(num_features = 512)
    self.conv_layer_14_bn = nn.BatchNorm2d(num_features = 1024)
    self.conv_layer_15_bn = nn.BatchNorm2d(num_features = 1024)
    self.conv_layer_16_bn = nn.BatchNorm2d(num_features = 256)


    self.max_pool_layer_1 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_2 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_3 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_4 = nn.MaxPool2d(kernel_size=2, stride = 2)
    self.max_pool_layer_5 = nn.MaxPool2d(kernel_size=2, stride = 2)

    self.fc_1 = nn.Linear(in_features = 12544, out_features = 4096)
    #self.fc_2 = nn.Linear(in_features = 4096, out_features = 4096) # NEW
    self.fc_3 = nn.Linear(in_features = 4096, out_features = self.n_classes)

    # Initialize the weights of each trainable layer of the network using xavier_uniform initialization
    def xavier_init(layer):
      for k,v in layer.named_parameters():
        if k == 'weight':
          init.xavier_uniform_(v)

    xavier_init(self.conv_layer_1)
    xavier_init(self.conv_layer_2)
    xavier_init(self.conv_layer_3)
    xavier_init(self.conv_layer_4)
    xavier_init(self.conv_layer_5)
    xavier_init(self.conv_layer_6)
    xavier_init(self.conv_layer_7)
    xavier_init(self.conv_layer_8)
    xavier_init(self.conv_layer_9)
    xavier_init(self.conv_layer_10)
    xavier_init(self.conv_layer_11)
    xavier_init(self.conv_layer_12)
    xavier_init(self.conv_layer_13)
    xavier_init(self.conv_layer_14) #NEW
    xavier_init(self.conv_layer_15) #NEW
    xavier_init(self.conv_layer_16) #NEW

    xavier_init(self.fc_1)
    #xavier_init(self.fc_2)
    xavier_init(self.fc_3)

  def activation(self, input):
    """
      input: Tensor
        Input on which the activation is applied.

      Output: Result of activation function applied on input.
        E.g. if self.activation_str is "relu", return relu(input).
    """
    if self.activation_str == "relu":
      a = nn.ReLU()
      return a(input)
    elif self.activation_str == "tanh":
      a = nn.Tanh()
      return a(input)
    else:
      raise Exception("Invalid activation")
    return 0


  def get_first_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the first convolution layer.
    """
    return self.conv_layer_1.weight.clone().cpu().detach().numpy()

  def get_13th_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the 13th convolution layer.
    """
    return self.conv_layer_13.weight.clone().cpu().detach().numpy()

  def get_last_conv_layer_filters(self):
    """
      Outputs: Returns the filters in the last convolution layer.
    """
    return self.conv_layer_16.weight.clone().cpu().detach().numpy()

  def forward(self, x):
    """
      x: Tensor
        Input to the network.

      Outputs: Returns the output of the forward pass of the network.
    """
    x = self.conv_layer_1(x)
    x = self.conv_layer_1_bn(x)
    x = self.activation(x)


    x = self.conv_layer_2(x)
    x = self.conv_layer_2_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_1(x)

    x = self.conv_layer_3(x)
    x = self.conv_layer_3_bn(x)
    x = self.activation(x)

    x = self.conv_layer_4(x)
    x = self.conv_layer_4_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_2(x)

    x = self.conv_layer_5(x)
    x = self.conv_layer_5_bn(x)
    x = self.activation(x)

    x = self.conv_layer_6(x)
    x = self.conv_layer_6_bn(x)
    x = self.activation(x)

    x = self.conv_layer_7(x)
    x = self.conv_layer_7_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_3(x)

    x = self.conv_layer_8(x)
    x = self.conv_layer_8_bn(x)
    x = self.activation(x)

    x = self.conv_layer_9(x)
    x = self.conv_layer_9_bn(x)
    x = self.activation(x)

    x = self.conv_layer_10(x)
    x = self.conv_layer_10_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_4(x)

    x = self.conv_layer_11(x)
    x = self.conv_layer_11_bn(x)
    x = self.activation(x)

    x = self.conv_layer_12(x)
    x = self.conv_layer_12_bn(x)
    x = self.activation(x)

    x = self.conv_layer_13(x)
    x = self.conv_layer_13_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_5(x)

    x = self.conv_layer_14(x)
    x = self.conv_layer_14_bn(x)
    x = self.activation(x)

    x = self.conv_layer_15(x)
    x = self.conv_layer_15_bn(x)
    x = self.activation(x)

    x = self.conv_layer_16(x)
    x = self.conv_layer_16_bn(x)
    x = self.activation(x)
    x = torch.flatten(x, start_dim = 1)

    #print("output shape before fc:",x.shape)

    x = self.fc_1(x)
    x = self.activation(x)
   # x = self.fc_2(x)
   # x = self.activation(x)
    x = self.fc_3(x)
    #x = self.activation(x)
    softmax = nn.Softmax(dim = 1)
    o = softmax(x)

    return o

  def last_conv(self,x):
    x = self.conv_layer_1(x)
    x = self.conv_layer_1_bn(x)
    x = self.activation(x)


    x = self.conv_layer_2(x)
    x = self.conv_layer_2_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_1(x)

    x = self.conv_layer_3(x)
    x = self.conv_layer_3_bn(x)
    x = self.activation(x)

    x = self.conv_layer_4(x)
    x = self.conv_layer_4_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_2(x)

    x = self.conv_layer_5(x)
    x = self.conv_layer_5_bn(x)
    x = self.activation(x)

    x = self.conv_layer_6(x)
    x = self.conv_layer_6_bn(x)
    x = self.activation(x)

    x = self.conv_layer_7(x)
    x = self.conv_layer_7_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_3(x)

    x = self.conv_layer_8(x)
    x = self.conv_layer_8_bn(x)
    x = self.activation(x)

    x = self.conv_layer_9(x)
    x = self.conv_layer_9_bn(x)
    x = self.activation(x)

    x = self.conv_layer_10(x)
    x = self.conv_layer_10_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_4(x)

    x = self.conv_layer_11(x)
    x = self.conv_layer_11_bn(x)
    x = self.activation(x)

    x = self.conv_layer_12(x)
    x = self.conv_layer_12_bn(x)
    x = self.activation(x)

    x = self.conv_layer_13(x)
    x = self.conv_layer_13_bn(x)
    x = self.activation(x)

    x = self.max_pool_layer_5(x)

    x = self.conv_layer_14(x)
    x = self.conv_layer_14_bn(x)
    x = self.activation(x)

    x = self.conv_layer_15(x)
    x = self.conv_layer_15_bn(x)
    x = self.activation(x)

    x = self.conv_layer_16(x)
    x = self.conv_layer_16_bn(x)
    x = self.activation(x)
    return x

```


```python
def get_cifar10():
  normalize = transforms.Normalize(
      mean=[0.4914, 0.4822, 0.4465],
      std=[0.2023, 0.1994, 0.2010],
  )

  # define transforms
  transform = transforms.Compose([
          transforms.Resize((227,227)),
          transforms.ToTensor(),
          normalize,
  ])

  train_dataset = torchvision.datasets.CIFAR10(
      root='./data', train=True, download=True, transform=transform)
  train_loader = torch.utils.data.DataLoader(
      train_dataset, batch_size=64, shuffle=True, num_workers=2)

  val_dataset = torchvision.datasets.CIFAR10(
      root='./data', train=False, download=True, transform=transform)
  val_loader = torch.utils.data.DataLoader(
      val_dataset, batch_size=64, shuffle=False, num_workers=2)

  return train_loader, val_loader

def train_loop(epoch, model, train_loader, criterion, optimizer):
  """
    epoch: int
      Number of the current training epoch (starting from 0).
    model: VGG16
      The model to train, which is an instance of the VGG16 class.
    train_loader: DataLoader
      The training dataloader.
    criterion: Module
      A Module object that evaluates the crossentropy loss.
    optimizer: Optimizer
      An Optimizer object for the Adam optimizer.

    Outputs: Returns average train_acc and train_loss for the current epoch.
  """
  train_acc = 0.
  train_loss = 0.
  counter = 0
  for batch in train_loader:
    for param in model.parameters(): # Recommended to save RAM
      param.grad = None
    x,y = batch
    if device == 'cuda':
      x = x.cuda()
      y = y.cuda()
    ans = model(x)
    loss = criterion(ans, y)
    loss.backward()
    optimizer.step()
    n = y.size(0)
    train_loss += loss.sum().data.cpu().numpy() * n
    counter += n
    if counter % 9984 == 0:
      print(f"iteration: {counter}")
    correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor)
    train_acc += correct
  train_acc /= counter
  train_loss /= counter
  print(f"Epoch: {epoch} | Train Acc: {train_acc:.6f} | Train Loss: {train_loss:.6f}")
  return train_acc, train_loss

def valid_loop(epoch, model, val_loader, criterion):
  """
    epoch: int
      Number of the current epoch (starting from 0).
    model: VGG16
      The model to train, which is an instance of the VGG16 class.
    val_loader: DataLoader
      The validation dataloader.
    criterion: Module
      A Module object that evaluates the crossentropy loss.

    Outputs: Returns average val_acc and val_loss for the current epoch.
  """
  val_acc = 0.
  val_loss = 0.
  counter = 0

  with torch.no_grad():
    for batch in val_loader:
      for param in model.parameters():
        param.grad = None
      x,y = batch
      if device == 'cuda':
        x = x.cuda()
        y = y.cuda()
      ans = model(x)
      loss = criterion(ans, y)
      n = y.size(0)
      val_loss += loss.sum().data.cpu().numpy() * n
      counter += n
      correct = (ans.argmax(1) == y).sum().type(torch.FloatTensor)
      val_acc += correct
    val_acc /= counter
    val_loss /= counter

  print(f"Epoch: {epoch} | Val Acc: {val_acc:.6f}   | Val Loss: {val_loss:.6f}")
  return val_acc, val_loss
```


```python
if __name__ == "__main__":
  activation_str = "relu"
  train_accs_new, train_losses_new, val_accs_new, val_losses_new = [], [], [], []
  n_epochs = 15

  newmodel = NewModel(
    activation_str=activation_str,
  ).to(device)
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(newmodel.parameters(), lr=0.001, momentum=0.9)
  summary(newmodel, (3, 227, 227))
  train_loader, val_loader = get_cifar10()

  training_newmodel = False
  new_model_save_name = 'newmodel.pt'
  path = F"/content/gdrive/My Drive/{new_model_save_name}"
  if training_newmodel:
    for epoch in range(n_epochs):
      # Training
      train_acc, train_loss = train_loop(epoch, newmodel, train_loader, criterion, optimizer)
      train_accs_new.append(train_acc)
      train_losses_new.append(train_loss)

      # Validation
      val_acc, val_loss = valid_loop(epoch, newmodel, val_loader, criterion)
      val_accs_new.append(val_acc)
      val_losses_new.append(val_loss)

    torch.save(newmodel.state_dict(), path)
  else:
    newmodel.load_state_dict(torch.load(path))
  newmodel.eval()
```

    ----------------------------------------------------------------
            Layer (type)               Output Shape         Param #
    ================================================================
                Conv2d-1         [-1, 64, 227, 227]           1,728
           BatchNorm2d-2         [-1, 64, 227, 227]             128
                Conv2d-3         [-1, 64, 227, 227]          36,864
           BatchNorm2d-4         [-1, 64, 227, 227]             128
             MaxPool2d-5         [-1, 64, 113, 113]               0
                Conv2d-6        [-1, 128, 113, 113]          73,728
           BatchNorm2d-7        [-1, 128, 113, 113]             256
                Conv2d-8        [-1, 128, 113, 113]         147,456
           BatchNorm2d-9        [-1, 128, 113, 113]             256
            MaxPool2d-10          [-1, 128, 56, 56]               0
               Conv2d-11          [-1, 256, 56, 56]         294,912
          BatchNorm2d-12          [-1, 256, 56, 56]             512
               Conv2d-13          [-1, 256, 56, 56]         589,824
          BatchNorm2d-14          [-1, 256, 56, 56]             512
               Conv2d-15          [-1, 256, 56, 56]         589,824
          BatchNorm2d-16          [-1, 256, 56, 56]             512
            MaxPool2d-17          [-1, 256, 28, 28]               0
               Conv2d-18          [-1, 512, 28, 28]       1,179,648
          BatchNorm2d-19          [-1, 512, 28, 28]           1,024
               Conv2d-20          [-1, 512, 28, 28]       2,359,296
          BatchNorm2d-21          [-1, 512, 28, 28]           1,024
               Conv2d-22          [-1, 512, 28, 28]       2,359,296
          BatchNorm2d-23          [-1, 512, 28, 28]           1,024
            MaxPool2d-24          [-1, 512, 14, 14]               0
               Conv2d-25          [-1, 512, 14, 14]       2,359,296
          BatchNorm2d-26          [-1, 512, 14, 14]           1,024
               Conv2d-27          [-1, 512, 14, 14]       2,359,296
          BatchNorm2d-28          [-1, 512, 14, 14]           1,024
               Conv2d-29          [-1, 512, 14, 14]       2,359,296
          BatchNorm2d-30          [-1, 512, 14, 14]           1,024
            MaxPool2d-31            [-1, 512, 7, 7]               0
               Conv2d-32           [-1, 1024, 7, 7]       4,718,592
          BatchNorm2d-33           [-1, 1024, 7, 7]           2,048
               Conv2d-34           [-1, 1024, 7, 7]       9,437,184
          BatchNorm2d-35           [-1, 1024, 7, 7]           2,048
               Conv2d-36            [-1, 256, 7, 7]         262,144
          BatchNorm2d-37            [-1, 256, 7, 7]             512
               Linear-38                 [-1, 4096]      51,384,320
               Linear-39                   [-1, 10]          40,970
    ================================================================
    Total params: 80,566,730
    Trainable params: 80,566,730
    Non-trainable params: 0
    ----------------------------------------------------------------
    Input size (MB): 0.59
    Forward/backward pass size (MB): 223.78
    Params size (MB): 307.34
    Estimated Total Size (MB): 531.71
    ----------------------------------------------------------------
    Files already downloaded and verified
    Files already downloaded and verified
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 0 | Train Acc: 0.390160 | Train Loss: 2.073157
    Epoch: 0 | Val Acc: 0.509200   | Val Loss: 1.959304
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 1 | Train Acc: 0.563660 | Train Loss: 1.906991
    Epoch: 1 | Val Acc: 0.592500   | Val Loss: 1.876027
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 2 | Train Acc: 0.640380 | Train Loss: 1.829771
    Epoch: 2 | Val Acc: 0.634900   | Val Loss: 1.830247
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 3 | Train Acc: 0.699220 | Train Loss: 1.771139
    Epoch: 3 | Val Acc: 0.675700   | Val Loss: 1.790679
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 4 | Train Acc: 0.752800 | Train Loss: 1.720363
    Epoch: 4 | Val Acc: 0.703600   | Val Loss: 1.763087
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 5 | Train Acc: 0.796740 | Train Loss: 1.677431
    Epoch: 5 | Val Acc: 0.731200   | Val Loss: 1.736286
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 6 | Train Acc: 0.837020 | Train Loss: 1.638283
    Epoch: 6 | Val Acc: 0.743500   | Val Loss: 1.725210
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 7 | Train Acc: 0.867340 | Train Loss: 1.608010
    Epoch: 7 | Val Acc: 0.759000   | Val Loss: 1.711229
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 8 | Train Acc: 0.892820 | Train Loss: 1.580717
    Epoch: 8 | Val Acc: 0.767300   | Val Loss: 1.702761
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 9 | Train Acc: 0.916600 | Train Loss: 1.556416
    Epoch: 9 | Val Acc: 0.771300   | Val Loss: 1.698747
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 10 | Train Acc: 0.934300 | Train Loss: 1.537240
    Epoch: 10 | Val Acc: 0.774300   | Val Loss: 1.692426
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 11 | Train Acc: 0.946000 | Train Loss: 1.523333
    Epoch: 11 | Val Acc: 0.779100   | Val Loss: 1.687521
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 12 | Train Acc: 0.953500 | Train Loss: 1.513713
    Epoch: 12 | Val Acc: 0.787300   | Val Loss: 1.681978
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 13 | Train Acc: 0.960300 | Train Loss: 1.505242
    Epoch: 13 | Val Acc: 0.787300   | Val Loss: 1.680611
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 14 | Train Acc: 0.964520 | Train Loss: 1.499856
    Epoch: 14 | Val Acc: 0.785600   | Val Loss: 1.681535



```python
data = [train_accs_new, train_losses_new, val_accs_new, val_losses_new,train_accs, train_losses, val_accs, val_losses]
labels = ["Other model training accuracy", "Other model training losses", "Other model validation accuracy", "Other model validation loss", "VGG16 training accuracy", "VGG16 training loss", "VGG16 validation accuracy", "VGG16 validation loss"]
```


```python
for index,values, in enumerate(data):
  if index %2==0:
    plt.plot(values, label = labels[index])
plt.title("Training and validation accuracy for both models")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()
for index,values, in enumerate(data):
  if index %2==1:
    plt.plot(values, label = labels[index])
plt.title("Training and validation losses for both models")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()
```



![png](output_34_0.png)





![png](output_34_1.png)




```python
def visualize_filters(model, last_or_first:str):
  if last_or_first == "last":
    weights = model.get_last_conv_layer_filters()
  elif last_or_first == "first":
    weights = model.get_first_conv_layer_filters()
  title = "VGG16 "+last_or_first+" filter" if isinstance(model, VGG16) else "New model "+last_or_first+" filter"

  f,ax = plt.subplots(3,3, figsize = (15,12))
  sns.heatmap(weights[0,0,:,:], ax = ax[0,0], annot = True).set(title = "filter 0, depth 0")
  sns.heatmap(weights[1,0,:,:], ax = ax[1,0], annot = True).set(title = "filter 1, depth 0")
  sns.heatmap(weights[2,0,:,:], ax = ax[2,0], annot = True).set(title = "filter 2, depth 0")
  sns.heatmap(weights[0,1,:,:], ax = ax[0,1], annot = True).set(title = "filter 0, depth 1")
  sns.heatmap(weights[1,1,:,:], ax = ax[1,1], annot = True).set(title = "filter 1, depth 1")
  sns.heatmap(weights[2,1,:,:], ax = ax[2,1], annot = True).set(title = "filter 2, depth 1")
  sns.heatmap(weights[0,2,:,:], ax = ax[0,2], annot = True).set(title = "filter 0, depth 2")
  sns.heatmap(weights[1,2,:,:], ax = ax[1,2], annot = True).set(title = "filter 1, depth 2")
  sns.heatmap(weights[2,2,:,:], ax = ax[2,2], annot = True).set(title = "filter 2, depth 2")
  f.suptitle(title)
  f.show()
print("new model, first layer")
visualize_filters(newmodel, "first")
print("new model, last layer")
visualize_filters(newmodel, "last")
print("VGG16, first layer")
visualize_filters(model, "first")
print("VGG16, last layer")
visualize_filters(model, "last")
```

    new model, first layer
    new model, last layer
    VGG16, first layer
    VGG16, last layer




![png](output_35_1.png)





![png](output_35_2.png)





![png](output_35_3.png)





![png](output_35_4.png)




```python
def visualize_feature_map(input, model, last_or_first:str):
  if last_or_first == "last":
    layer = model.last_conv

  elif last_or_first == "first":
    layer = model.conv_layer_1
    bn_layer = model.conv_layer_1_bn
  title = "VGG16 " + last_or_first + " feature map" if isinstance(model, VGG16) else "New model " + last_or_first + " feature map"

  x = layer(input.cuda())
  if last_or_first == "first":
    x = bn_layer(x)
    x = model.activation(x)
  x = x.squeeze()
  x = x.cpu().detach().numpy()
  f,ax = plt.subplots(3,1, figsize = (15,12))
  ax[0].imshow(x[0,:,:])#, title = "Feature map from filter 0")
  ax[1].imshow(x[1,:,:])#, title = "Feature map from filter 1")
  ax[2].imshow(x[2,:,:])#, title = "Feature map from filter 2")
  ax[0].set_title("Feature map from filter 0")
  ax[1].set_title("Feature map from filter 1")
  ax[2].set_title("Feature map from filter 2")
  ax[0].set_xticks([])
  ax[0].set_yticks([])
  ax[1].set_xticks([])
  ax[1].set_yticks([])
  ax[2].set_xticks([])
  ax[2].set_yticks([])
  f.suptitle(title)
  f.show()
```


```python
print("newmodel first feature map:")
visualize_feature_map(vis_image, model= newmodel, last_or_first = "first")
print("newmodel last feature map:")
visualize_feature_map(vis_image, model= newmodel, last_or_first = "last")
print("VGG16 first feature map:")
visualize_feature_map(vis_image, model= model, last_or_first = "first")
print("VGG16 last feature map:")
visualize_feature_map(vis_image, model= model, last_or_first = "last")
```

    newmodel first feature map:
    newmodel last feature map:
    VGG16 first feature map:
    VGG16 last feature map:




![png](output_37_1.png)





![png](output_37_2.png)





![png](output_37_3.png)





![png](output_37_4.png)




```python
if __name__ == "__main__":
  train_accs_mlp, train_losses_mlp, val_accs_mlp, val_losses_mlp = [], [], [], []
  n_epochs = 15

  mlpmodel = nn.Sequential(
      nn.Flatten(),
      nn.Linear(154587, 900),
      nn.ReLU(),
      nn.Linear(900, 100),
      nn.ReLU(),
      nn.Linear(100, 10),
      nn.Softmax(),
    ).to(device)
  criterion = nn.CrossEntropyLoss()
  optimizer = optim.SGD(mlpmodel.parameters(), lr=0.001, momentum=0.9)
  summary(mlpmodel, (3, 227, 227))
  train_loader, val_loader = get_cifar10()

  training_mlpmodel = True
  new_model_save_name = 'mlpmodel.pt'
  path = F"/content/gdrive/My Drive/{new_model_save_name}"
  if training_mlpmodel:
    for epoch in range(n_epochs):
      # Training
      train_acc, train_loss = train_loop(epoch, mlpmodel, train_loader, criterion, optimizer)
      train_accs_mlp.append(train_acc)
      train_losses_mlp.append(train_loss)

      # Validation
      val_acc, val_loss = valid_loop(epoch, mlpmodel, val_loader, criterion)
      val_accs_mlp.append(val_acc)
      val_losses_mlp.append(val_loss)

    torch.save(mlpmodel.state_dict(), path)
  else:
    mlpmodel.load_state_dict(torch.load(path))#CNN: 4600 secs, VGG16: 4700 secs, mlp 747 seconds
```

    /usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:217: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
      input = module(input)


    ----------------------------------------------------------------
            Layer (type)               Output Shape         Param #
    ================================================================
               Flatten-1               [-1, 154587]               0
                Linear-2                  [-1, 900]     139,129,200
                  ReLU-3                  [-1, 900]               0
                Linear-4                  [-1, 100]          90,100
                  ReLU-5                  [-1, 100]               0
                Linear-6                   [-1, 10]           1,010
               Softmax-7                   [-1, 10]               0
    ================================================================
    Total params: 139,220,310
    Trainable params: 139,220,310
    Non-trainable params: 0
    ----------------------------------------------------------------
    Input size (MB): 0.59
    Forward/backward pass size (MB): 1.19
    Params size (MB): 531.08
    Estimated Total Size (MB): 532.87
    ----------------------------------------------------------------
    Files already downloaded and verified
    Files already downloaded and verified
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 0 | Train Acc: 0.356940 | Train Loss: 2.110807
    Epoch: 0 | Val Acc: 0.414400   | Val Loss: 2.052695
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 1 | Train Acc: 0.424720 | Train Loss: 2.039178
    Epoch: 1 | Val Acc: 0.438100   | Val Loss: 2.023829
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 2 | Train Acc: 0.459260 | Train Loss: 2.006578
    Epoch: 2 | Val Acc: 0.458600   | Val Loss: 2.004817
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 3 | Train Acc: 0.479600 | Train Loss: 1.984926
    Epoch: 3 | Val Acc: 0.465600   | Val Loss: 1.995198
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 4 | Train Acc: 0.500140 | Train Loss: 1.965256
    Epoch: 4 | Val Acc: 0.479100   | Val Loss: 1.982158
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 5 | Train Acc: 0.519100 | Train Loss: 1.947724
    Epoch: 5 | Val Acc: 0.482000   | Val Loss: 1.976624
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 6 | Train Acc: 0.533740 | Train Loss: 1.933568
    Epoch: 6 | Val Acc: 0.488400   | Val Loss: 1.969442
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 7 | Train Acc: 0.547720 | Train Loss: 1.919642
    Epoch: 7 | Val Acc: 0.498700   | Val Loss: 1.961227
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 8 | Train Acc: 0.560240 | Train Loss: 1.907547
    Epoch: 8 | Val Acc: 0.493500   | Val Loss: 1.964206
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 9 | Train Acc: 0.570880 | Train Loss: 1.896523
    Epoch: 9 | Val Acc: 0.503900   | Val Loss: 1.954599
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 10 | Train Acc: 0.581920 | Train Loss: 1.885764
    Epoch: 10 | Val Acc: 0.504500   | Val Loss: 1.951931
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 11 | Train Acc: 0.590400 | Train Loss: 1.876387
    Epoch: 11 | Val Acc: 0.508800   | Val Loss: 1.949614
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 12 | Train Acc: 0.601980 | Train Loss: 1.865941
    Epoch: 12 | Val Acc: 0.512600   | Val Loss: 1.947000
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 13 | Train Acc: 0.610980 | Train Loss: 1.857660
    Epoch: 13 | Val Acc: 0.512400   | Val Loss: 1.945281
    iteration: 9984
    iteration: 19968
    iteration: 29952
    iteration: 39936
    iteration: 49920
    Epoch: 14 | Train Acc: 0.618980 | Train Loss: 1.849438
    Epoch: 14 | Val Acc: 0.512400   | Val Loss: 1.944758



```python
new_data = [train_accs_mlp, train_losses_mlp, val_accs_mlp, val_losses_mlp, train_accs_new, train_losses_new, val_accs_new, val_losses_new]
new_labels = ["MLP training accuracy", "MLP training losses", "MLP validation accuracy", "MLP validation loss", "CNN training accuracy", "CNN training loss", "CNN validation accuracy", "CNN validation loss"]
for index,values, in enumerate(new_data):
  if index%2 == 0:
    plt.plot(values, label = new_labels[index])
plt.title("Training and validation accuracy for both models")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()
for index,values, in enumerate(new_data):
    if index%2 == 1:
      plt.plot(values, label = new_labels[index])
plt.title("Training and validation losses for both models")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.show()
```



![png](output_39_0.png)





![png](output_39_1.png)




```python
image = np.moveaxis(vis_image.squeeze().cpu().detach().numpy(), 0, -1)
plt.imshow(image)
plt.title("Original image")
plt.xticks([])
plt.yticks([])
plt.show()
```

    WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).




![png](output_40_1.png)


